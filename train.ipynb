{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ±ðŸ¶ Cat/Dog Classifier with MLflow Tracking\n",
                "\n",
                "This notebook demonstrates MLOps best practices:\n",
                "- **ResNet-18** fine-tuning for cat/dog classification\n",
                "- **MLflow** for experiment tracking (params, metrics, artifacts)\n",
                "- Comprehensive metrics: Accuracy, Precision, Recall, F1, AUC-ROC\n",
                "\n",
                "## How to Use\n",
                "1. Run all cells to train and log to MLflow\n",
                "2. Open MLflow UI: `mlflow ui` in terminal\n",
                "3. Compare experiments at http://localhost:5000"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# CONFIGURATION - Modify these for experiments\n",
                "# ==========================================\n",
                "\n",
                "# Hyperparameters\n",
                "LEARNING_RATE = 0.001      # Try: 0.001, 0.0001, 0.00001\n",
                "EPOCHS = 5                 # Try: 5, 10, 15\n",
                "BATCH_SIZE = 16            # Try: 8, 16, 32\n",
                "\n",
                "# Model configuration\n",
                "UNFREEZE_LAYER4 = False    # Set True for Phase 3 (more data)\n",
                "\n",
                "# Data version tag (for tracking)\n",
                "DATA_VERSION = \"v1\"        # Update when data changes: v1, v2, etc."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# IMPORTS\n",
                "# ==========================================\n",
                "import os\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader, random_split\n",
                "from torchvision import datasets, transforms, models\n",
                "import mlflow\n",
                "import mlflow.pytorch\n",
                "from sklearn.metrics import (\n",
                "    confusion_matrix, classification_report,\n",
                "    precision_score, recall_score, f1_score,\n",
                "    roc_auc_score, roc_curve\n",
                ")\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import numpy as np\n",
                "from datetime import datetime\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"MLflow version: {mlflow.__version__}\")\n",
                "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# DATA LOADING\n",
                "# ==========================================\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "\n",
                "# Transforms for ResNet-18\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(\n",
                "        mean=[0.485, 0.456, 0.406],\n",
                "        std=[0.229, 0.224, 0.225]\n",
                "    )\n",
                "])\n",
                "\n",
                "# Load dataset from data/ folder\n",
                "dataset = datasets.ImageFolder('data/', transform=transform)\n",
                "print(f\"Classes: {dataset.classes}\")\n",
                "print(f\"Total images: {len(dataset)}\")\n",
                "\n",
                "# Train/Val split (80/20)\n",
                "train_size = int(0.8 * len(dataset))\n",
                "val_size = len(dataset) - train_size\n",
                "train_dataset, val_dataset = random_split(\n",
                "    dataset, [train_size, val_size],\n",
                "    generator=torch.Generator().manual_seed(42)\n",
                ")\n",
                "\n",
                "print(f\"Training samples: {len(train_dataset)}\")\n",
                "print(f\"Validation samples: {len(val_dataset)}\")\n",
                "\n",
                "# DataLoaders\n",
                "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
                "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# MODEL SETUP\n",
                "# ==========================================\n",
                "\n",
                "# Load pretrained ResNet-18\n",
                "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
                "\n",
                "# Freeze all layers first\n",
                "for param in model.parameters():\n",
                "    param.requires_grad = False\n",
                "\n",
                "# Optionally unfreeze layer4 (for Phase 3 with more data)\n",
                "if UNFREEZE_LAYER4:\n",
                "    for param in model.layer4.parameters():\n",
                "        param.requires_grad = True\n",
                "    print(\"âœ“ Layer4 UNFROZEN - fine-tuning enabled\")\n",
                "else:\n",
                "    print(\"âœ“ All layers FROZEN - feature extraction only\")\n",
                "\n",
                "# Replace classifier for binary classification (Cat=0, Dog=1)\n",
                "model.fc = nn.Linear(model.fc.in_features, 2)\n",
                "\n",
                "# Move to device\n",
                "model = model.to(device)\n",
                "\n",
                "# Count parameters\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f\"Total parameters: {total_params:,}\")\n",
                "print(f\"Trainable parameters: {trainable_params:,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# TRAINING FUNCTIONS\n",
                "# ==========================================\n",
                "\n",
                "def train_one_epoch(model, loader, criterion, optimizer):\n",
                "    model.train()\n",
                "    running_loss = 0.0\n",
                "    correct = 0\n",
                "    total = 0\n",
                "    \n",
                "    for images, labels in loader:\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(images)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        running_loss += loss.item() * images.size(0)\n",
                "        _, predicted = outputs.max(1)\n",
                "        total += labels.size(0)\n",
                "        correct += predicted.eq(labels).sum().item()\n",
                "    \n",
                "    return running_loss / total, correct / total\n",
                "\n",
                "\n",
                "def evaluate(model, loader, criterion):\n",
                "    model.eval()\n",
                "    running_loss = 0.0\n",
                "    all_labels = []\n",
                "    all_preds = []\n",
                "    all_probs = []\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        for images, labels in loader:\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "            \n",
                "            running_loss += loss.item() * images.size(0)\n",
                "            probs = torch.softmax(outputs, dim=1)\n",
                "            _, predicted = outputs.max(1)\n",
                "            \n",
                "            all_labels.extend(labels.cpu().numpy())\n",
                "            all_preds.extend(predicted.cpu().numpy())\n",
                "            all_probs.extend(probs[:, 1].cpu().numpy())  # Prob of Dog class\n",
                "    \n",
                "    return {\n",
                "        'loss': running_loss / len(loader.dataset),\n",
                "        'labels': np.array(all_labels),\n",
                "        'predictions': np.array(all_preds),\n",
                "        'probabilities': np.array(all_probs)\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# VISUALIZATION FUNCTIONS\n",
                "# ==========================================\n",
                "\n",
                "def plot_confusion_matrix(labels, predictions, classes):\n",
                "    \"\"\"Create and save confusion matrix plot.\"\"\"\n",
                "    cm = confusion_matrix(labels, predictions)\n",
                "    plt.figure(figsize=(8, 6))\n",
                "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
                "                xticklabels=classes, yticklabels=classes)\n",
                "    plt.xlabel('Predicted')\n",
                "    plt.ylabel('Actual')\n",
                "    plt.title('Confusion Matrix')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig('confusion_matrix.png', dpi=150)\n",
                "    plt.close()\n",
                "    return 'confusion_matrix.png'\n",
                "\n",
                "\n",
                "def plot_roc_curve(labels, probabilities):\n",
                "    \"\"\"Create and save ROC curve plot.\"\"\"\n",
                "    fpr, tpr, _ = roc_curve(labels, probabilities)\n",
                "    auc = roc_auc_score(labels, probabilities)\n",
                "    \n",
                "    plt.figure(figsize=(8, 6))\n",
                "    plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC (AUC = {auc:.3f})')\n",
                "    plt.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
                "    plt.xlim([0, 1])\n",
                "    plt.ylim([0, 1.05])\n",
                "    plt.xlabel('False Positive Rate')\n",
                "    plt.ylabel('True Positive Rate')\n",
                "    plt.title('ROC Curve')\n",
                "    plt.legend(loc='lower right')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig('roc_curve.png', dpi=150)\n",
                "    plt.close()\n",
                "    return 'roc_curve.png'\n",
                "\n",
                "\n",
                "def plot_training_curves(train_losses, val_losses, val_accs):\n",
                "    \"\"\"Create and save training curves plot.\"\"\"\n",
                "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
                "    \n",
                "    epochs = range(1, len(train_losses) + 1)\n",
                "    \n",
                "    ax1.plot(epochs, train_losses, 'b-', label='Train Loss')\n",
                "    ax1.plot(epochs, val_losses, 'r-', label='Val Loss')\n",
                "    ax1.set_xlabel('Epoch')\n",
                "    ax1.set_ylabel('Loss')\n",
                "    ax1.set_title('Loss Curves')\n",
                "    ax1.legend()\n",
                "    \n",
                "    ax2.plot(epochs, val_accs, 'g-', label='Val Accuracy')\n",
                "    ax2.set_xlabel('Epoch')\n",
                "    ax2.set_ylabel('Accuracy')\n",
                "    ax2.set_title('Validation Accuracy')\n",
                "    ax2.legend()\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig('training_curves.png', dpi=150)\n",
                "    plt.close()\n",
                "    return 'training_curves.png'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# TRAINING WITH MLFLOW TRACKING\n",
                "# ==========================================\n",
                "\n",
                "# Set experiment name\n",
                "mlflow.set_experiment(\"Cat-Dog-Classifier\")\n",
                "\n",
                "# Create run name with timestamp\n",
                "run_name = f\"resnet18-{DATA_VERSION}-{datetime.now().strftime('%H%M')}\"\n",
                "\n",
                "with mlflow.start_run(run_name=run_name):\n",
                "    # ===== LOG PARAMETERS =====\n",
                "    mlflow.log_params({\n",
                "        \"learning_rate\": LEARNING_RATE,\n",
                "        \"epochs\": EPOCHS,\n",
                "        \"batch_size\": BATCH_SIZE,\n",
                "        \"model\": \"resnet18\",\n",
                "        \"pretrained\": True,\n",
                "        \"unfreeze_layer4\": UNFREEZE_LAYER4,\n",
                "        \"data_version\": DATA_VERSION,\n",
                "        \"train_samples\": len(train_dataset),\n",
                "        \"val_samples\": len(val_dataset),\n",
                "        \"total_params\": total_params,\n",
                "        \"trainable_params\": trainable_params\n",
                "    })\n",
                "    \n",
                "    # Tags for organization\n",
                "    mlflow.set_tag(\"task\", \"binary_classification\")\n",
                "    mlflow.set_tag(\"framework\", \"pytorch\")\n",
                "    \n",
                "    # Setup training\n",
                "    criterion = nn.CrossEntropyLoss()\n",
                "    optimizer = optim.Adam(\n",
                "        filter(lambda p: p.requires_grad, model.parameters()),\n",
                "        lr=LEARNING_RATE\n",
                "    )\n",
                "    \n",
                "    # Training history\n",
                "    train_losses, val_losses, val_accs = [], [], []\n",
                "    best_val_acc = 0.0\n",
                "    \n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"Training: {run_name}\")\n",
                "    print(f\"Data: {len(train_dataset)} train, {len(val_dataset)} val\")\n",
                "    print(f\"{'='*50}\\n\")\n",
                "    \n",
                "    # ===== TRAINING LOOP =====\n",
                "    for epoch in range(EPOCHS):\n",
                "        # Train\n",
                "        train_loss, train_acc = train_one_epoch(\n",
                "            model, train_loader, criterion, optimizer\n",
                "        )\n",
                "        \n",
                "        # Evaluate\n",
                "        val_results = evaluate(model, val_loader, criterion)\n",
                "        val_loss = val_results['loss']\n",
                "        val_acc = (val_results['predictions'] == val_results['labels']).mean()\n",
                "        \n",
                "        # Store history\n",
                "        train_losses.append(train_loss)\n",
                "        val_losses.append(val_loss)\n",
                "        val_accs.append(val_acc)\n",
                "        \n",
                "        # Log metrics per epoch\n",
                "        mlflow.log_metrics({\n",
                "            \"train_loss\": train_loss,\n",
                "            \"train_acc\": train_acc,\n",
                "            \"val_loss\": val_loss,\n",
                "            \"val_acc\": val_acc\n",
                "        }, step=epoch)\n",
                "        \n",
                "        # Track best\n",
                "        if val_acc > best_val_acc:\n",
                "            best_val_acc = val_acc\n",
                "        \n",
                "        print(f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
                "              f\"Train Loss: {train_loss:.4f} | \"\n",
                "              f\"Val Loss: {val_loss:.4f} | \"\n",
                "              f\"Val Acc: {val_acc:.4f}\")\n",
                "    \n",
                "    # ===== FINAL EVALUATION =====\n",
                "    final_results = evaluate(model, val_loader, criterion)\n",
                "    labels = final_results['labels']\n",
                "    preds = final_results['predictions']\n",
                "    probs = final_results['probabilities']\n",
                "    \n",
                "    # Calculate comprehensive metrics\n",
                "    accuracy = (preds == labels).mean()\n",
                "    precision = precision_score(labels, preds, average='binary')\n",
                "    recall = recall_score(labels, preds, average='binary')\n",
                "    f1 = f1_score(labels, preds, average='binary')\n",
                "    auc = roc_auc_score(labels, probs)\n",
                "    \n",
                "    # Log final metrics\n",
                "    mlflow.log_metrics({\n",
                "        \"final_accuracy\": accuracy,\n",
                "        \"precision\": precision,\n",
                "        \"recall\": recall,\n",
                "        \"f1_score\": f1,\n",
                "        \"auc_roc\": auc,\n",
                "        \"best_val_acc\": best_val_acc\n",
                "    })\n",
                "    \n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(\"FINAL METRICS\")\n",
                "    print(f\"{'='*50}\")\n",
                "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
                "    print(f\"Precision: {precision:.4f}\")\n",
                "    print(f\"Recall:    {recall:.4f}\")\n",
                "    print(f\"F1 Score:  {f1:.4f}\")\n",
                "    print(f\"AUC-ROC:   {auc:.4f}\")\n",
                "    \n",
                "    # ===== LOG ARTIFACTS =====\n",
                "    # Confusion Matrix\n",
                "    cm_path = plot_confusion_matrix(labels, preds, dataset.classes)\n",
                "    mlflow.log_artifact(cm_path)\n",
                "    print(f\"\\nâœ“ Logged: {cm_path}\")\n",
                "    \n",
                "    # ROC Curve\n",
                "    roc_path = plot_roc_curve(labels, probs)\n",
                "    mlflow.log_artifact(roc_path)\n",
                "    print(f\"âœ“ Logged: {roc_path}\")\n",
                "    \n",
                "    # Training Curves\n",
                "    curves_path = plot_training_curves(train_losses, val_losses, val_accs)\n",
                "    mlflow.log_artifact(curves_path)\n",
                "    print(f\"âœ“ Logged: {curves_path}\")\n",
                "    \n",
                "    # Save and log model\n",
                "    os.makedirs('models', exist_ok=True)\n",
                "    model_path = f'models/model_{DATA_VERSION}.pth'\n",
                "    torch.save(model.state_dict(), model_path)\n",
                "    mlflow.log_artifact(model_path)\n",
                "    print(f\"âœ“ Logged: {model_path}\")\n",
                "    \n",
                "    # Log model with MLflow format\n",
                "    mlflow.pytorch.log_model(model, \"pytorch_model\")\n",
                "    print(f\"âœ“ Logged: MLflow PyTorch model\")\n",
                "    \n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"Run ID: {mlflow.active_run().info.run_id}\")\n",
                "    print(f\"View at: mlflow ui\")\n",
                "    print(f\"{'='*50}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==========================================\n",
                "# CLASSIFICATION REPORT\n",
                "# ==========================================\n",
                "print(\"\\nDetailed Classification Report:\")\n",
                "print(classification_report(labels, preds, target_names=dataset.classes))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## ðŸ“‹ Next Steps\n",
                "\n",
                "### Phase 2: Hyperparameter Tuning\n",
                "1. Change `LEARNING_RATE` to `0.0001`\n",
                "2. Change `EPOCHS` to `10`\n",
                "3. Run all cells again\n",
                "4. Compare runs in MLflow UI\n",
                "\n",
                "### Phase 3: More Data + Unfreeze Layer4\n",
                "1. Add more images to `data/Cat/` and `data/Dog/`\n",
                "2. Run: `dvc add data/` and `git commit`\n",
                "3. Set `UNFREEZE_LAYER4 = True`\n",
                "4. Update `DATA_VERSION = \"v2\"`\n",
                "5. Run all cells again\n",
                "6. Compare all runs in MLflow UI"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}